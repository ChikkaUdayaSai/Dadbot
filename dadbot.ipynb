{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# Dadbot: Dad's memorial bot based on RASA (old style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "## Starting Jupyter Notebook with necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_7gOmu0r3v",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "# Installations\n",
    "* Rasa\n",
    "* SpaCy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "UsvAOHF_1dAY",
    "outputId": "f65c2c83-e7ae-46ef-e800-e43dcb854766",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "#!{python} -m pip install -U pip\n",
    "#!{python} -m pip install rasa[convert]~=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wyCva14-1gD4",
    "outputId": "642d04c1-b9ad-4ed0-fb28-ee9bef21507b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!{python} -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Downloading the Spanish Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eRmnEdML3OhH",
    "outputId": "cb852307-d652-40c3-cf3d-66c54f833908",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!{python} -m spacy link es_core_news_md es --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Import the Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu"
   },
   "outputs": [],
   "source": [
    "import rasa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "# 1. Teaching the bot to understand user inputs using Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "## Training the NLU Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rasa.nlu.model:Starting to train component WhitespaceTokenizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component RegexFeaturizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component LexicalSyntacticFeaturizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component CountVectorsFeaturizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component CountVectorsFeaturizer\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component DIETClassifier\n",
      "Epochs: 100%|██████████| 100/100 [01:14<00:00,  1.35it/s, t_loss=1.497, i_acc=0.991, e_f1=0.997]\n",
      "INFO:rasa.utils.tensorflow.models:Finished training.\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component EntitySynonymMapper\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component ResponseSelector\n",
      "INFO:rasa.nlu.selectors.response_selector:Retrieval intent parameter was left to its default value. This response selector will be trained on training examples combining all retrieval intents.\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Starting to train component FallbackClassifier\n",
      "INFO:rasa.nlu.model:Finished training component.\n",
      "INFO:rasa.nlu.model:Successfully saved model into '/home/debian/workspace/Dadbot/models/current'\n"
     ]
    }
   ],
   "source": [
    "from rasa.model import get_model\n",
    "from rasa.shared.nlu.training_data.loading import load_data\n",
    "from rasa.shared.core.slots import Slot, TextSlot\n",
    "from rasa.shared.core.domain import Domain\n",
    "from rasa.nlu import config, utils\n",
    "from rasa.nlu.components import ComponentBuilder\n",
    "from rasa.nlu.config import RasaNLUModelConfig\n",
    "from rasa.nlu.model import Interpreter, Trainer, TrainingData\n",
    "from rasa.nlu.components import Component\n",
    "from rasa.nlu.tokenizers.tokenizer import Token\n",
    "from rasa.utils.tensorflow.constants import ENTITY_RECOGNITION\n",
    "\n",
    "import spacy\n",
    "\n",
    "#spacy_parser = spacy.load('es_core_news_md')\n",
    "#nlp = spacy.load('es')\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"data/nlu/nlu.yml\")\n",
    "\n",
    "# trainer to train our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "## Evaluating the NLU model on a random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"dejándome el coche\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "## Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rasa.nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu/nlu.yml\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "# 2. Teaching the bot to respond using Rasa Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "##  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXZhTaSw9SNR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "#!breq install graphviz\n",
    "\n",
    "#!conda install -y -n rasa pygraphviz pkg-config;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa.core.agent import Agent\n",
    " \n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"data/core/stories.yml\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "## Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed story blocks: 100%|██████████| 30/30 [00:00<00:00, 1026.36it/s, # trackers=1]\n",
      "Processed story blocks: 100%|██████████| 30/30 [00:00<00:00, 124.18it/s, # trackers=29]\n",
      "Processed story blocks: 100%|██████████| 30/30 [00:00<00:00, 65.26it/s, # trackers=50]\n",
      "Processed story blocks: 100%|██████████| 30/30 [00:00<00:00, 43.74it/s, # trackers=50]\n",
      "Processed trackers: 100%|██████████| 29/29 [00:00<00:00, 340.37it/s, # actions=147]\n",
      "Processed actions: 147it [00:00, 2578.31it/s, # examples=143]\n",
      "Processed trackers: 0it [00:00, ?it/s]\n",
      "Processed trackers: 100%|██████████| 29/29 [00:00<00:00, 356.04it/s, # actions=147]\n",
      "Processed trackers: 100%|██████████| 29/29 [00:00<00:00, 2212.95it/s]\n",
      "INFO:rasa.core.agent:Model directory ./models/core exists and contains old model files. All files will be overwritten.\n",
      "INFO:rasa.core.agent:Persisted model to '/home/debian/workspace/Dadbot/models/core'\n"
     ]
    }
   ],
   "source": [
    "from rasa.core.policies.policy import Policy\n",
    "from rasa.core.policies.registry import RulePolicy, MemoizationPolicy, FallbackPolicy, TEDPolicy\n",
    "from rasa.core.agent import Agent\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "# Deprecated\n",
    "#fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "#                          core_threshold=0.2,\n",
    "#                          nlu_threshold=0.1)\n",
    "\n",
    "agent = Agent('domain.yml',\n",
    "              policies=[MemoizationPolicy(max_history=5),\n",
    "                        RulePolicy()])\n",
    "#                        fallback])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = await agent.load_data('data/core/stories.yml')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "agent.persist('./models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "# Talk to your Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817"
   },
   "outputs": [],
   "source": [
    "#Starting the Bot\n",
    "from rasa.core.agent import Agent\n",
    "from rasa.core.utils import EndpointConfig\n",
    "\n",
    "action_endpoint = EndpointConfig(url=\"http://0.0.0.0:5055/webhook\")\n",
    "agent = Agent.load('./models/', interpreter=model_directory, action_endpoint=action_endpoint)\n",
    "\n",
    "#!docker run -d -p 5055:5055 --mount type=bind,source=/home/debian/workspace/Dadbot/actions,target=/app/actions rasa/rasa-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the voice synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/NVIDIA/tacotron2.git\n",
    "#!git clone https://github.com/DeepLearningExamples/CUDA-Optimized/FastSpeech.git\n",
    "#!ln -s DeepLearningExamples/CUDA-Optimized/FastSpeech/fastspeech fastspeech\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tacotron2.hparams import create_hparams\n",
    "from tacotron2.model import Tacotron2\n",
    "from tacotron2.stft import STFT\n",
    "from tacotron2.audio_processing import griffin_lim\n",
    "from tacotron2.train import load_model\n",
    "from tacotron2.waveglow.mel2samp import files_to_list, MAX_WAV_VALUE\n",
    "from tacotron2.waveglow.glow import WaveGlow\n",
    "from fastspeech.inferencer.denoiser import Denoiser\n",
    "from fastspeech.text_norm import text_to_sequence\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('tacotron2/waveglow/')\n",
    "\n",
    "def synthesize(text, voice, sigma=0.6, denoiser_strength=0.05, is_fp16=False):\n",
    "\n",
    "    hparams = create_hparams()\n",
    "    hparams.sampling_rate = 22050\n",
    "\n",
    "    if voice == \"papaito\":\n",
    "        voice_model = \"nvidia_tacotron2_papaito_300\"\n",
    "    elif voice == \"constantino\":\n",
    "        voice_model = \"tacotron2_Constantino_600\"\n",
    "    elif voice == \"orador\":\n",
    "        voice_model = \"checkpoint_tacotron2_29000_es\"\n",
    "    \n",
    "    checkpoint_path = \"/home/debian/workspace/models/\" + voice_model\n",
    "        \n",
    "    model = load_model(hparams)\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "    _ = model.cuda().eval().half()\n",
    "\n",
    "    waveglow_path = '/home/debian/workspace/models/waveglow_256channels_ljs_v2.pt'\n",
    "    waveglow = torch.load(waveglow_path)['model']\n",
    "    _ = waveglow.cuda().eval().half()\n",
    "    denoiser = Denoiser(waveglow)\n",
    "\n",
    "    #text=\"¡Cágate lorito!\"\n",
    "    #with open(filelist_path, encoding='utf-8', mode='r') as f:\n",
    "    #    text = f.read()\n",
    "\n",
    "    sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(\n",
    "        torch.from_numpy(sequence)).cuda().long()\n",
    "\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "    #mel = torch.unsqueeze(mel, 0)\n",
    "    mel = mel_outputs.half() if is_fp16 else mel_outputs\n",
    "    audio = np.array([])\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel, sigma=sigma)\n",
    "        if denoiser_strength > 0:\n",
    "             audio = denoiser(audio, denoiser_strength)\n",
    "        audio = audio * MAX_WAV_VALUE\n",
    "        audio = audio.squeeze()\n",
    "        audio = audio.cpu().numpy()\n",
    "        audio = audio.astype('int16')\n",
    "    \n",
    "    return audio, hparams.sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Dadbot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\n",
      "hola\n",
      "\u001b[34m¿Qué tal?\u001b[39m\n",
      "bien\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from sty import fg, bg, ef, rs\n",
    "\n",
    "print(\"¡Dadbot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    \n",
    "    if a == 'quieto parao':\n",
    "        break\n",
    "    responses = await agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        to_synth = response[\"text\"]\n",
    "        #to_synth = \"Esto es una prueba para ver si funciona\"\n",
    "        print(fg.blue + to_synth + fg.rs)\n",
    "        response_file = open('response.txt','w') \n",
    "        response_file.write(to_synth)\n",
    "        voice, sr = synthesize(to_synth, \"orador\")\n",
    "        sd.play(voice, sr)\n",
    "        response_file.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Conversational_Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('rasa')",
   "language": "python",
   "name": "python37764bitrasa723bfee6806b4490a1c7314aabcac412"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
