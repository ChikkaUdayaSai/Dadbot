{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# Dadbot: Dad's memorial bot based on RASA (old style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "## Starting Jupyter Notebook with necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_7gOmu0r3v",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "# Installations\n",
    "* Rasa\n",
    "* SpaCy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "UsvAOHF_1dAY",
    "outputId": "f65c2c83-e7ae-46ef-e800-e43dcb854766",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "#!{python} -m pip install -U pip\n",
    "#!{python} -m pip install tensorflow[tensorflow-addons]==2.1.0\n",
    "#!{python} -m pip install rasa[convert]~=1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wyCva14-1gD4",
    "outputId": "642d04c1-b9ad-4ed0-fb28-ee9bef21507b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: es_core_news_md==2.2.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.2.0/es_core_news_md-2.2.0.tar.gz#egg=es_core_news_md==2.2.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (2.2.0)\nRequirement already satisfied: spacy>=2.2.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from es_core_news_md==2.2.0) (2.2.1)\nRequirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (7.1.1)\nRequirement already satisfied: blis<0.5.0,>=0.4.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (0.4.1)\nRequirement already satisfied: plac<1.0.0,>=0.9.6 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (0.9.6)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/debian/.local/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (2.24.0)\nRequirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (1.0.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (3.0.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (1.0.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (2.0.3)\nRequirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (0.6.0)\nRequirement already satisfied: numpy>=1.15.0 in /home/debian/.local/lib/python3.7/site-packages (from spacy>=2.2.0->es_core_news_md==2.2.0) (1.18.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/debian/.local/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->es_core_news_md==2.2.0) (4.45.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->es_core_news_md==2.2.0) (2020.6.20)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->es_core_news_md==2.2.0) (3.0.4)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->es_core_news_md==2.2.0) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /home/debian/.conda/envs/rasa/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->es_core_news_md==2.2.0) (2.9)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\nYou should consider upgrading via the '/home/debian/.conda/envs/rasa/bin/python -m pip install --upgrade pip' command.\u001b[0m\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('es_core_news_md')\n"
    }
   ],
   "source": [
    "!{python} -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Downloading the Spanish Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eRmnEdML3OhH",
    "outputId": "cb852307-d652-40c3-cf3d-66c54f833908",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[38;5;2m✔ Linking successful\u001b[0m\n/home/debian/.conda/envs/rasa/lib/python3.7/site-packages/es_core_news_md -->\n/home/debian/.conda/envs/rasa/lib/python3.7/site-packages/spacy/data/es\nYou can now load the model via spacy.load('es')\n"
    }
   ],
   "source": [
    "!{python} -m spacy link es_core_news_md es --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Import the Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu"
   },
   "outputs": [],
   "source": [
    "import rasa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "# 1. Teaching the bot to understand user inputs using Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "## Training the NLU Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:rasa.nlu.model:Starting to train component WhitespaceTokenizer\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component RegexFeaturizer\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component CRFEntityExtractor\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component EntitySynonymMapper\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component CountVectorsFeaturizer\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component CountVectorsFeaturizer\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Starting to train component EmbeddingIntentClassifier\nEpochs: 100%|██████████| 300/300 [00:35<00:00,  8.36it/s, t_loss=1.127, i_loss=0.112, i_acc=0.992]\nINFO:rasa.utils.tensorflow.models:Finished training.\nINFO:rasa.nlu.model:Finished training component.\nINFO:rasa.nlu.model:Successfully saved model into '/home/debian/workspace/Dadbot/models/nlu/current'\n"
    }
   ],
   "source": [
    "from rasa.model import get_model\n",
    "from rasa.nlu import config, training_data, utils\n",
    "from rasa.nlu.utils import write_to_file\n",
    "from rasa.nlu.components import ComponentBuilder\n",
    "from rasa.nlu.config import RasaNLUModelConfig\n",
    "from rasa.nlu.model import Interpreter, Trainer, TrainingData\n",
    "from rasa.nlu.components import Component\n",
    "from rasa.nlu.tokenizers.tokenizer import Token\n",
    "from rasa.utils.tensorflow.constants import ENTITY_RECOGNITION\n",
    "\n",
    "import spacy\n",
    "\n",
    "#spacy_parser = spacy.load('es_core_news_md')\n",
    "#nlp = spacy.load('es')\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = training_data.loading.load_data(\"data/nlu/nlu-papaito.md\")\n",
    "\n",
    "# trainer to train our pipeline\n",
    "trainer = Trainer(config.load(\"config_simple.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "## Evaluating the NLU model on a random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{\n  \"intent\": {\n    \"name\": \"ask_help\",\n    \"confidence\": 0.961948037147522\n  },\n  \"entities\": [],\n  \"intent_ranking\": [\n    {\n      \"name\": \"ask_help\",\n      \"confidence\": 0.961948037147522\n    },\n    {\n      \"name\": \"inform_estado\",\n      \"confidence\": 0.01379871740937233\n    },\n    {\n      \"name\": \"ask_deporte_futbol\",\n      \"confidence\": 0.005939386319369078\n    },\n    {\n      \"name\": \"ask_vivienda\",\n      \"confidence\": 0.003995127975940704\n    },\n    {\n      \"name\": \"ask_cuenta_algo\",\n      \"confidence\": 0.0036021017003804445\n    },\n    {\n      \"name\": \"ask_pais\",\n      \"confidence\": 0.002997576491907239\n    },\n    {\n      \"name\": \"mood_deny\",\n      \"confidence\": 0.0024529730435460806\n    },\n    {\n      \"name\": \"ask_nombre\",\n      \"confidence\": 0.0020948059391230345\n    },\n    {\n      \"name\": \"goodbye\",\n      \"confidence\": 0.0019319221610203385\n    },\n    {\n      \"name\": \"ask_deporte_bici\",\n      \"confidence\": 0.0012393814977258444\n    }\n  ],\n  \"text\": \"dej\\u00e1ndome el coche\"\n}\n"
    }
   ],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"dejándome el coche\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "## Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:rasa.nlu.test:Running model for predictions:\n100%|██████████| 612/612 [00:01<00:00, 361.63it/s]\nINFO:rasa.nlu.test:Intent evaluation results:\nINFO:rasa.nlu.test:Intent Evaluation: Only considering those 612 examples that have a defined intent out of 612 examples\nINFO:rasa.nlu.test:F1-Score:  0.9885429120500552\nINFO:rasa.nlu.test:Precision: 0.9887066365007543\nINFO:rasa.nlu.test:Accuracy:  0.988562091503268\nINFO:rasa.nlu.test:Classification report: \n                      precision    recall  f1-score   support\n\n    ask_deporte_bici       1.00      1.00      1.00         9\n          ask_estado       1.00      1.00      1.00        31\n        ask_vivienda       1.00      1.00      1.00        13\n        mood_unhappy       0.99      0.99      0.99        87\n       inform_estado       1.00      1.00      1.00        10\n         mood_affirm       1.00      1.00      1.00        42\n          mood_happy       1.00      0.98      0.99        51\n            ask_pais       1.00      1.00      1.00         8\n               greet       0.95      0.95      0.95        42\n          ask_nombre       1.00      1.00      1.00        15\n  ask_deporte_futbol       1.00      1.00      1.00         5\n       ask_ocupacion       1.00      1.00      1.00        14\n             goodbye       0.97      0.97      0.97        33\n            ask_help       1.00      1.00      1.00        38\n     inform_pregunta       1.00      1.00      1.00        23\n       inform_comida       1.00      0.89      0.94         9\n          ask_gustos       1.00      1.00      1.00         4\nask_ultimas_noticias       1.00      1.00      1.00        22\n       inform_ciudad       1.00      1.00      1.00        14\n           mood_deny       0.95      1.00      0.97        19\n           ask_razon       1.00      1.00      1.00        12\n          ask_comida       0.96      1.00      0.98        25\n       ask_actividad       1.00      1.00      1.00        67\n     ask_cuenta_algo       0.95      0.95      0.95        19\n\n            accuracy                           0.99       612\n           macro avg       0.99      0.99      0.99       612\n        weighted avg       0.99      0.99      0.99       612\n\nINFO:rasa.nlu.test:Entity evaluation results:\nINFO:rasa.nlu.test:Evaluation for entity extractor: CRFEntityExtractor \nINFO:rasa.nlu.test:F1-Score:  0.9620713153743609\nINFO:rasa.nlu.test:Precision: 0.9636257366224944\nINFO:rasa.nlu.test:Accuracy:  0.9971751412429378\nINFO:rasa.nlu.test:Classification report: \n              precision    recall  f1-score   support\n\n        cosa       1.00      0.71      0.83         7\n      ciudad       1.00      1.00      1.00        18\n     horario       0.95      1.00      0.98        21\n      famoso       1.00      1.00      1.00        14\n   actividad       0.94      1.00      0.97        16\n     deporte       1.00      0.60      0.75         5\n      comida       0.86      1.00      0.92         6\n       salud       1.00      1.00      1.00        12\n       plato       0.93      1.00      0.97        28\n\n   micro avg       0.96      0.97      0.96       127\n   macro avg       0.97      0.92      0.94       127\nweighted avg       0.96      0.97      0.96       127\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ntent': 'ask_help',\n    'predicted': 'ask_help',\n    'confidence': 0.9768481850624084},\n   {'text': 'prestándome el coche',\n    'intent': 'ask_help',\n    'predicted': 'ask_help',\n    'confidence': 0.995529294013977},\n   {'text': 'dejandome el coche',\n    'intent': 'ask_help',\n    'predicted': 'ask_help',\n    'confidence': 0.9930726885795593},\n   {'text': '¿por qué?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9968084096908569},\n   {'text': '¿por qué no?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9927771091461182},\n   {'text': '¿por?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9567881226539612},\n   {'text': 'dime por qué',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9789391160011292},\n   {'text': 'dime el porqué',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9872432947158813},\n   {'text': 'quiero que me lo cuentes',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9945124387741089},\n   {'text': 'dímelo',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9898421168327332},\n   {'text': '¿por qué qué?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9989882111549377},\n   {'text': '¿el qué?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9876078963279724},\n   {'text': '¿a qué?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9706913232803345},\n   {'text': '¿qué?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9452940225601196},\n   {'text': '¿y eso?',\n    'intent': 'ask_razon',\n    'predicted': 'ask_razon',\n    'confidence': 0.9642914533615112},\n   {'text': '¿qué te cuentas?',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.4946005046367645},\n   {'text': 'cuéntate algo',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9779546856880188},\n   {'text': 'te cuentas algo',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9609975814819336},\n   {'text': 'dime',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'greet',\n    'confidence': 0.5427666902542114},\n   {'text': 'dime algo',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9765311479568481},\n   {'text': '¿no te cuentas nada?',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9827816486358643},\n   {'text': 'dime a ver',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9691867828369141},\n   {'text': '¿qué pasó?',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9858638048171997},\n   {'text': 'no te cuentas nada',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9827816486358643},\n   {'text': 'no te vas a contar nada',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9779200553894043},\n   {'text': 'no me dices nada',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9542549848556519},\n   {'text': 'no te vayas',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9769947528839111},\n   {'text': 'no me dejes',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9512904286384583},\n   {'text': 'no te vayas todavía',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9896253943443298},\n   {'text': 'no me dejes todavía',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9850736856460571},\n   {'text': 'no te vayas aún',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9879591464996338},\n   {'text': 'no me dejes aún',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9822942018508911},\n   {'text': 'espera',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9782338738441467},\n   {'text': 'espera un poco',\n    'intent': 'ask_cuenta_algo',\n    'predicted': 'ask_cuenta_algo',\n    'confidence': 0.9826366901397705},\n   {'text': '¿qué has hecho hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9905418157577515},\n   {'text': 'qué has hecho hoy',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9905418157577515},\n   {'text': 'que has hecho hoy',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9936596751213074},\n   {'text': 'qué has hecho',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9591478705406189},\n   {'text': 'has salido hoy',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.996938169002533},\n   {'text': '¿te has ido por ahí?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9813334941864014},\n   {'text': '¿has salido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9947732090950012},\n   {'text': '¿no has salido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9855685830116272},\n   {'text': '¿ya has salido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9881348013877869},\n   {'text': '¿has salido hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.996938169002533},\n   {'text': '¿no has salido hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9928548336029053},\n   {'text': '¿vas a salir?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9975411891937256},\n   {'text': '¿vas a venir?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9858958721160889},\n   {'text': '¿vas a salir después?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9933257102966309},\n   {'text': '¿vas a salir luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9971804022789001},\n   {'text': '¿vas a venir luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9862601161003113},\n   {'text': '¿vas a salir hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9983147382736206},\n   {'text': '¿vas a salir mañana?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9953916072845459},\n   {'text': '¿vas a salir ahora?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9718481302261353},\n   {'text': '¿vas a salir por la tarde?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9857751131057739},\n   {'text': '¿vas a salir en un rato?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9928145408630371},\n   {'text': '¿vas a salir un rato?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9956690073013306},\n   {'text': '¿no sales hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9779039025306702},\n   {'text': '¿no sales luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9512858986854553},\n   {'text': '¿sales luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9818552732467651},\n   {'text': '¿sales?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9779019355773926},\n   {'text': '¿sales hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.99062180519104},\n   {'text': '¿sales con la bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.994478166103363},\n   {'text': '¿sales con la bicicleta?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9913136959075928},\n   {'text': '¿sales un rato?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9716941714286804},\n   {'text': 'que te traes',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9747582077980042},\n   {'text': 'qué te traes',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9578071236610413},\n   {'text': '¿qué haces?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.931546151638031},\n   {'text': '¿qué estás haciendo?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9578767418861389},\n   {'text': '¿qué vas a hacer?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9816612601280212},\n   {'text': '¿qué vas a hacer hoy?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9950388073921204},\n   {'text': '¿qué vas a hacer luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9918279051780701},\n   {'text': 'que haces',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9703424572944641},\n   {'text': '¿dónde has ido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9697578549385071},\n   {'text': '¿te has ido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9931172132492065},\n   {'text': '¿has ido a andar?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9940692782402039},\n   {'text': '¿has salido a caminar?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9912256598472595},\n   {'text': '¿has ido a correr?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.992940366268158},\n   {'text': '¿has salido a correr?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9927520155906677},\n   {'text': '¿has ido a montar en bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9981591105461121},\n   {'text': '¿has salido a montar en bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9976072907447815},\n   {'text': '¿has salido con la bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9979036450386047},\n   {'text': '¿has salido con la bicicleta?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.996342658996582},\n   {'text': '¿has cogido la bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9927971363067627},\n   {'text': '¿vas a montar en bici?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9563875198364258},\n   {'text': '¿has visto el partido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9834999442100525},\n   {'text': '¿vas a ver el partido?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9855250716209412},\n   {'text': '¿vas a ver el partido luego?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9855426549911499},\n   {'text': '¿vas a ver la tele?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9732010960578918},\n   {'text': '¿vas a ver la televisión?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9932134747505188},\n   {'text': '¿vas a ver la televisión después?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9904369115829468},\n   {'text': '¿estás viendo la tele?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9827959537506104},\n   {'text': '¿estás viendo la televisión?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9937022924423218},\n   {'text': '¿has hecho de vientre?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9960495829582214},\n   {'text': '¿has hecho ya de vientre?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9930883646011353},\n   {'text': '¿hiciste de vientre?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9756941199302673},\n   {'text': '¿has hecho ejercicio?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9901174902915955},\n   {'text': '¿vas a hacer ejercicio?',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9952496886253357},\n   {'text': 'haz ejercicio',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9779872894287109},\n   {'text': 'haz de vientre',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9907333254814148},\n   {'text': 'bebe agua',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9736919403076172},\n   {'text': 'bebe más agua',\n    'intent': 'ask_actividad',\n    'predicted': 'ask_actividad',\n    'confidence': 0.9747333526611328},\n   {'text': '¿has visto las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9975325465202332},\n   {'text': '¿has oído las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9982084631919861},\n   {'text': '¿has escuchado las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9979466795921326},\n   {'text': '¿te has enterado de las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9995149374008179},\n   {'text': '¿te has enterado lo que ha pasado?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9874767065048218},\n   {'text': '¿sabes cuales son las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9966017007827759},\n   {'text': '¿sabes las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9957101345062256},\n   {'text': '¿sabes las últimas noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9975619912147522},\n   {'text': 'ponme al día',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9934743046760559},\n   {'text': 'por favor ponme al día',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9951511025428772},\n   {'text': '¿me puedes poner al día?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9980457425117493},\n   {'text': '¿estás al día?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9887199401855469},\n   {'text': '¿estás al tanto de las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.998913049697876},\n   {'text': 'dame las noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9971973299980164},\n   {'text': 'dime las noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9894561171531677},\n   {'text': 'cuéntame las noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9969027638435364},\n   {'text': 'dame las últimas noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9982563853263855},\n   {'text': 'dime las últimas noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9952827095985413},\n   {'text': '¿me das las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9973278045654297},\n   {'text': '¿me puedes dar las noticias?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9964310526847839},\n   {'text': '¿me puedes dar las noticias por favor?',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9974620938301086},\n   {'text': 'por favor las noticias',\n    'intent': 'ask_ultimas_noticias',\n    'predicted': 'ask_ultimas_noticias',\n    'confidence': 0.9975875616073608}],\n  'report': '                      precision    recall  f1-score   support\\n\\n    ask_deporte_bici       1.00      1.00      1.00         9\\n          ask_estado       1.00      1.00      1.00        31\\n        ask_vivienda       1.00      1.00      1.00        13\\n        mood_unhappy       0.99      0.99      0.99        87\\n       inform_estado       1.00      1.00      1.00        10\\n         mood_affirm       1.00      1.00      1.00        42\\n          mood_happy       1.00      0.98      0.99        51\\n            ask_pais       1.00      1.00      1.00         8\\n               greet       0.95      0.95      0.95        42\\n          ask_nombre       1.00      1.00      1.00        15\\n  ask_deporte_futbol       1.00      1.00      1.00         5\\n       ask_ocupacion       1.00      1.00      1.00        14\\n             goodbye       0.97      0.97      0.97        33\\n            ask_help       1.00      1.00      1.00        38\\n     inform_pregunta       1.00      1.00      1.00        23\\n       inform_comida       1.00      0.89      0.94         9\\n          ask_gustos       1.00      1.00      1.00         4\\nask_ultimas_noticias       1.00      1.00      1.00        22\\n       inform_ciudad       1.00      1.00      1.00        14\\n           mood_deny       0.95      1.00      0.97        19\\n           ask_razon       1.00      1.00      1.00        12\\n          ask_comida       0.96      1.00      0.98        25\\n       ask_actividad       1.00      1.00      1.00        67\\n     ask_cuenta_algo       0.95      0.95      0.95        19\\n\\n            accuracy                           0.99       612\\n           macro avg       0.99      0.99      0.99       612\\n        weighted avg       0.99      0.99      0.99       612\\n',\n  'precision': 0.9887066365007543,\n  'f1_score': 0.9885429120500552,\n  'accuracy': 0.988562091503268},\n 'entity_evaluation': {'CRFEntityExtractor': {'report': '              precision    recall  f1-score   support\\n\\n        cosa       1.00      0.71      0.83         7\\n      ciudad       1.00      1.00      1.00        18\\n     horario       0.95      1.00      0.98        21\\n      famoso       1.00      1.00      1.00        14\\n   actividad       0.94      1.00      0.97        16\\n     deporte       1.00      0.60      0.75         5\\n      comida       0.86      1.00      0.92         6\\n       salud       1.00      1.00      1.00        12\\n       plato       0.93      1.00      0.97        28\\n\\n   micro avg       0.96      0.97      0.96       127\\n   macro avg       0.97      0.92      0.94       127\\nweighted avg       0.96      0.97      0.96       127\\n',\n   'precision': 0.9636257366224944,\n   'f1_score': 0.9620713153743609,\n   'accuracy': 0.9971751412429378}},\n 'response_selection_evaluation': None}"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "from rasa.nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu/nlu-papaito.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "# 2. Teaching the bot to respond using Rasa Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "##  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXZhTaSw9SNR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "#!breq install graphviz\n",
    "\n",
    "#!conda install -y -n rasa pygraphviz pkg-config;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa.core.agent import Agent\n",
    " \n",
    "agent = Agent('domain-papaito.yml')\n",
    "#agent.visualize(\"data/core/stories-papaito.md\", \"story_graph.png\", max_history=2)\n",
    "#Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "## Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "curacy: 0.9364\nEpoch 219/400\n1430/1430 [==============================] - 0s 144us/sample - loss: 0.2006 - accuracy: 0.9273\nEpoch 220/400\n1430/1430 [==============================] - 0s 122us/sample - loss: 0.2182 - accuracy: 0.9175\nEpoch 221/400\n1430/1430 [==============================] - 0s 198us/sample - loss: 0.1901 - accuracy: 0.9308\nEpoch 222/400\n1430/1430 [==============================] - 0s 149us/sample - loss: 0.1636 - accuracy: 0.9427\nEpoch 223/400\n1430/1430 [==============================] - 0s 133us/sample - loss: 0.2053 - accuracy: 0.9259\nEpoch 224/400\n1430/1430 [==============================] - 0s 135us/sample - loss: 0.2114 - accuracy: 0.9273\nEpoch 225/400\n1430/1430 [==============================] - 0s 129us/sample - loss: 0.2009 - accuracy: 0.9308\nEpoch 226/400\n1430/1430 [==============================] - 0s 137us/sample - loss: 0.2305 - accuracy: 0.9203\nEpoch 227/400\n1430/1430 [==============================] - 0s 137us/sample - loss: 0.2031 - accuracy: 0.9308\nEpoch 228/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1846 - accuracy: 0.9301\nEpoch 229/400\n1430/1430 [==============================] - 0s 127us/sample - loss: 0.2013 - accuracy: 0.9301\nEpoch 230/400\n1430/1430 [==============================] - 0s 124us/sample - loss: 0.2201 - accuracy: 0.9273\nEpoch 231/400\n1430/1430 [==============================] - 0s 132us/sample - loss: 0.1933 - accuracy: 0.9224\nEpoch 232/400\n1430/1430 [==============================] - 0s 108us/sample - loss: 0.2110 - accuracy: 0.9210\nEpoch 233/400\n1430/1430 [==============================] - 0s 116us/sample - loss: 0.2169 - accuracy: 0.9238\nEpoch 234/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.1857 - accuracy: 0.9273\nEpoch 235/400\n1430/1430 [==============================] - 0s 117us/sample - loss: 0.2317 - accuracy: 0.9168\nEpoch 236/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.2157 - accuracy: 0.9245\nEpoch 237/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.2057 - accuracy: 0.9273\nEpoch 238/400\n1430/1430 [==============================] - 0s 112us/sample - loss: 0.1927 - accuracy: 0.9336\nEpoch 239/400\n1430/1430 [==============================] - 0s 123us/sample - loss: 0.1971 - accuracy: 0.9301\nEpoch 240/400\n1430/1430 [==============================] - 0s 116us/sample - loss: 0.2068 - accuracy: 0.9336\nEpoch 241/400\n1430/1430 [==============================] - 0s 121us/sample - loss: 0.1983 - accuracy: 0.9266\nEpoch 242/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.2360 - accuracy: 0.9119\nEpoch 243/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.1747 - accuracy: 0.9357\nEpoch 244/400\n1430/1430 [==============================] - 0s 174us/sample - loss: 0.2007 - accuracy: 0.9301\nEpoch 245/400\n1430/1430 [==============================] - 0s 157us/sample - loss: 0.1948 - accuracy: 0.9357\nEpoch 246/400\n1430/1430 [==============================] - 0s 147us/sample - loss: 0.2025 - accuracy: 0.9280\nEpoch 247/400\n1430/1430 [==============================] - 0s 136us/sample - loss: 0.1996 - accuracy: 0.9301\nEpoch 248/400\n1430/1430 [==============================] - 0s 136us/sample - loss: 0.2164 - accuracy: 0.9266\nEpoch 249/400\n1430/1430 [==============================] - 0s 142us/sample - loss: 0.1974 - accuracy: 0.9308\nEpoch 250/400\n1430/1430 [==============================] - 0s 138us/sample - loss: 0.2064 - accuracy: 0.9224\nEpoch 251/400\n1430/1430 [==============================] - 0s 126us/sample - loss: 0.2065 - accuracy: 0.9238\nEpoch 252/400\n1430/1430 [==============================] - 0s 122us/sample - loss: 0.2226 - accuracy: 0.9231\nEpoch 253/400\n1430/1430 [==============================] - 0s 134us/sample - loss: 0.2089 - accuracy: 0.9266\nEpoch 254/400\n1430/1430 [==============================] - 0s 132us/sample - loss: 0.1675 - accuracy: 0.9385\nEpoch 255/400\n1430/1430 [==============================] - 0s 116us/sample - loss: 0.2084 - accuracy: 0.9210\nEpoch 256/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1714 - accuracy: 0.9399\nEpoch 257/400\n1430/1430 [==============================] - 0s 129us/sample - loss: 0.1958 - accuracy: 0.9280\nEpoch 258/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.1987 - accuracy: 0.9266\nEpoch 259/400\n1430/1430 [==============================] - 0s 117us/sample - loss: 0.1926 - accuracy: 0.9315\nEpoch 260/400\n1430/1430 [==============================] - 0s 133us/sample - loss: 0.1997 - accuracy: 0.9266\nEpoch 261/400\n1430/1430 [==============================] - 0s 134us/sample - loss: 0.1939 - accuracy: 0.9357\nEpoch 262/400\n1430/1430 [==============================] - 0s 121us/sample - loss: 0.2051 - accuracy: 0.9245\nEpoch 263/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.1778 - accuracy: 0.9357\nEpoch 264/400\n1430/1430 [==============================] - 0s 112us/sample - loss: 0.2091 - accuracy: 0.9231\nEpoch 265/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.1943 - accuracy: 0.9280\nEpoch 266/400\n1430/1430 [==============================] - 0s 128us/sample - loss: 0.1655 - accuracy: 0.9392\nEpoch 267/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.2094 - accuracy: 0.9210\nEpoch 268/400\n1430/1430 [==============================] - 0s 122us/sample - loss: 0.1999 - accuracy: 0.9294\nEpoch 269/400\n1430/1430 [==============================] - 0s 125us/sample - loss: 0.1841 - accuracy: 0.9259\nEpoch 270/400\n1430/1430 [==============================] - 0s 155us/sample - loss: 0.1899 - accuracy: 0.9315\nEpoch 271/400\n1430/1430 [==============================] - 0s 147us/sample - loss: 0.2102 - accuracy: 0.9224\nEpoch 272/400\n1430/1430 [==============================] - 0s 151us/sample - loss: 0.2263 - accuracy: 0.9182\nEpoch 273/400\n1430/1430 [==============================] - 0s 143us/sample - loss: 0.2198 - accuracy: 0.9175\nEpoch 274/400\n1430/1430 [==============================] - 0s 128us/sample - loss: 0.1824 - accuracy: 0.9350\nEpoch 275/400\n1430/1430 [==============================] - 0s 117us/sample - loss: 0.2033 - accuracy: 0.9259\nEpoch 276/400\n1430/1430 [==============================] - 0s 122us/sample - loss: 0.1793 - accuracy: 0.9336\nEpoch 277/400\n1430/1430 [==============================] - 0s 126us/sample - loss: 0.2076 - accuracy: 0.9280\nEpoch 278/400\n1430/1430 [==============================] - 0s 125us/sample - loss: 0.1876 - accuracy: 0.9350\nEpoch 279/400\n1430/1430 [==============================] - 0s 107us/sample - loss: 0.1911 - accuracy: 0.9280\nEpoch 280/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.2045 - accuracy: 0.9259\nEpoch 281/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.1750 - accuracy: 0.9357\nEpoch 282/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1880 - accuracy: 0.9301\nEpoch 283/400\n1430/1430 [==============================] - 0s 117us/sample - loss: 0.2137 - accuracy: 0.9210\nEpoch 284/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.2092 - accuracy: 0.9280\nEpoch 285/400\n1430/1430 [==============================] - 0s 97us/sample - loss: 0.1734 - accuracy: 0.9301\nEpoch 286/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.1512 - accuracy: 0.9455\nEpoch 287/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1735 - accuracy: 0.9364\nEpoch 288/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1793 - accuracy: 0.9315\nEpoch 289/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1773 - accuracy: 0.9343\nEpoch 290/400\n1430/1430 [==============================] - 0s 115us/sample - loss: 0.2008 - accuracy: 0.9266\nEpoch 291/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1863 - accuracy: 0.9301\nEpoch 292/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1772 - accuracy: 0.9357\nEpoch 293/400\n1430/1430 [==============================] - 0s 103us/sample - loss: 0.2076 - accuracy: 0.9238\nEpoch 294/400\n1430/1430 [==============================] - 0s 139us/sample - loss: 0.1838 - accuracy: 0.9357\nEpoch 295/400\n1430/1430 [==============================] - 0s 112us/sample - loss: 0.1895 - accuracy: 0.9315\nEpoch 296/400\n1430/1430 [==============================] - 0s 113us/sample - loss: 0.1929 - accuracy: 0.9308\nEpoch 297/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1972 - accuracy: 0.9301\nEpoch 298/400\n1430/1430 [==============================] - 0s 114us/sample - loss: 0.1864 - accuracy: 0.9266\nEpoch 299/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1628 - accuracy: 0.9378\nEpoch 300/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1913 - accuracy: 0.9224\nEpoch 301/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.2129 - accuracy: 0.9231\nEpoch 302/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1968 - accuracy: 0.9287\nEpoch 303/400\n1430/1430 [==============================] - 0s 125us/sample - loss: 0.1695 - accuracy: 0.9343\nEpoch 304/400\n1430/1430 [==============================] - 0s 115us/sample - loss: 0.1883 - accuracy: 0.9329\nEpoch 305/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1492 - accuracy: 0.9441\nEpoch 306/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1855 - accuracy: 0.9329\nEpoch 307/400\n1430/1430 [==============================] - 0s 108us/sample - loss: 0.1922 - accuracy: 0.9322\nEpoch 308/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.2006 - accuracy: 0.9252\nEpoch 309/400\n1430/1430 [==============================] - 0s 148us/sample - loss: 0.1945 - accuracy: 0.9294\nEpoch 310/400\n1430/1430 [==============================] - 0s 118us/sample - loss: 0.1835 - accuracy: 0.9350\nEpoch 311/400\n1430/1430 [==============================] - 0s 121us/sample - loss: 0.2022 - accuracy: 0.9238\nEpoch 312/400\n1430/1430 [==============================] - 0s 109us/sample - loss: 0.1905 - accuracy: 0.9308\nEpoch 313/400\n1430/1430 [==============================] - 0s 102us/sample - loss: 0.1824 - accuracy: 0.9280\nEpoch 314/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1937 - accuracy: 0.9301\nEpoch 315/400\n1430/1430 [==============================] - 0s 102us/sample - loss: 0.1909 - accuracy: 0.9266\nEpoch 316/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1725 - accuracy: 0.9420\nEpoch 317/400\n1430/1430 [==============================] - 0s 115us/sample - loss: 0.2006 - accuracy: 0.9231\nEpoch 318/400\n1430/1430 [==============================] - 0s 111us/sample - loss: 0.1641 - accuracy: 0.9357\nEpoch 319/400\n1430/1430 [==============================] - 0s 125us/sample - loss: 0.2199 - accuracy: 0.9238\nEpoch 320/400\n1430/1430 [==============================] - 0s 120us/sample - loss: 0.2056 - accuracy: 0.9273\nEpoch 321/400\n1430/1430 [==============================] - 0s 122us/sample - loss: 0.1890 - accuracy: 0.9308\nEpoch 322/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.1823 - accuracy: 0.9280\nEpoch 323/400\n1430/1430 [==============================] - 0s 116us/sample - loss: 0.1884 - accuracy: 0.9287\nEpoch 324/400\n1430/1430 [==============================] - 0s 109us/sample - loss: 0.1862 - accuracy: 0.9343\nEpoch 325/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1837 - accuracy: 0.9315\nEpoch 326/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1943 - accuracy: 0.9287\nEpoch 327/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1898 - accuracy: 0.9329\nEpoch 328/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.2108 - accuracy: 0.9217\nEpoch 329/400\n1430/1430 [==============================] - 0s 121us/sample - loss: 0.1765 - accuracy: 0.9371\nEpoch 330/400\n1430/1430 [==============================] - 0s 110us/sample - loss: 0.2232 - accuracy: 0.9189\nEpoch 331/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.2067 - accuracy: 0.9231\nEpoch 332/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.2106 - accuracy: 0.9189\nEpoch 333/400\n1430/1430 [==============================] - 0s 107us/sample - loss: 0.2414 - accuracy: 0.9147\nEpoch 334/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1959 - accuracy: 0.9287\nEpoch 335/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1738 - accuracy: 0.9399\nEpoch 336/400\n1430/1430 [==============================] - 0s 107us/sample - loss: 0.2086 - accuracy: 0.9196\nEpoch 337/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1618 - accuracy: 0.9378\nEpoch 338/400\n1430/1430 [==============================] - 0s 97us/sample - loss: 0.1798 - accuracy: 0.9385\nEpoch 339/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.1907 - accuracy: 0.9252\nEpoch 340/400\n1430/1430 [==============================] - 0s 97us/sample - loss: 0.1866 - accuracy: 0.9315\nEpoch 341/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1728 - accuracy: 0.9336\nEpoch 342/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1800 - accuracy: 0.9329\nEpoch 343/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.1764 - accuracy: 0.9308\nEpoch 344/400\n1430/1430 [==============================] - 0s 102us/sample - loss: 0.1939 - accuracy: 0.9273\nEpoch 345/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1727 - accuracy: 0.9308\nEpoch 346/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1928 - accuracy: 0.9315\nEpoch 347/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.1885 - accuracy: 0.9315\nEpoch 348/400\n1430/1430 [==============================] - 0s 95us/sample - loss: 0.1686 - accuracy: 0.9371\nEpoch 349/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1880 - accuracy: 0.9273\nEpoch 350/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1968 - accuracy: 0.9189\nEpoch 351/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1611 - accuracy: 0.9392\nEpoch 352/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1626 - accuracy: 0.9413\nEpoch 353/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.2021 - accuracy: 0.9238\nEpoch 354/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1982 - accuracy: 0.9266\nEpoch 355/400\n1430/1430 [==============================] - 0s 117us/sample - loss: 0.1908 - accuracy: 0.9252\nEpoch 356/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.1747 - accuracy: 0.9350\nEpoch 357/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.2085 - accuracy: 0.9231\nEpoch 358/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.2021 - accuracy: 0.9308\nEpoch 359/400\n1430/1430 [==============================] - 0s 132us/sample - loss: 0.1880 - accuracy: 0.9343\nEpoch 360/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.2014 - accuracy: 0.9273\nEpoch 361/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1773 - accuracy: 0.9378\nEpoch 362/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1950 - accuracy: 0.9238\nEpoch 363/400\n1430/1430 [==============================] - 0s 109us/sample - loss: 0.1934 - accuracy: 0.9308\nEpoch 364/400\n1430/1430 [==============================] - 0s 121us/sample - loss: 0.1918 - accuracy: 0.9287\nEpoch 365/400\n1430/1430 [==============================] - 0s 114us/sample - loss: 0.1853 - accuracy: 0.9308\nEpoch 366/400\n1430/1430 [==============================] - 0s 109us/sample - loss: 0.1826 - accuracy: 0.9315\nEpoch 367/400\n1088/1430 [=====================>........] - ETA: 0s - loss: 0.1930 - accuracy: 0.921430/1430 [==============================] - 0s 107us/sample - loss: 0.1854 - accuracy: 0.9308\nEpoch 368/400\n1430/1430 [==============================] - 0s 110us/sample - loss: 0.1696 - accuracy: 0.9336\nEpoch 369/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1936 - accuracy: 0.9329\nEpoch 370/400\n1430/1430 [==============================] - 0s 108us/sample - loss: 0.1928 - accuracy: 0.9259\nEpoch 371/400\n1430/1430 [==============================] - 0s 113us/sample - loss: 0.1877 - accuracy: 0.9294\nEpoch 372/400\n1430/1430 [==============================] - 0s 119us/sample - loss: 0.1776 - accuracy: 0.9294\nEpoch 373/400\n1430/1430 [==============================] - 0s 123us/sample - loss: 0.1883 - accuracy: 0.9287\nEpoch 374/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1493 - accuracy: 0.9441\nEpoch 375/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1744 - accuracy: 0.9350\nEpoch 376/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1856 - accuracy: 0.9350\nEpoch 377/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1771 - accuracy: 0.9350\nEpoch 378/400\n1430/1430 [==============================] - 0s 112us/sample - loss: 0.1747 - accuracy: 0.9378\nEpoch 379/400\n1430/1430 [==============================] - 0s 103us/sample - loss: 0.1800 - accuracy: 0.9371\nEpoch 380/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1988 - accuracy: 0.9336\nEpoch 381/400\n1430/1430 [==============================] - 0s 110us/sample - loss: 0.1804 - accuracy: 0.9280\nEpoch 382/400\n1430/1430 [==============================] - 0s 105us/sample - loss: 0.1853 - accuracy: 0.9350\nEpoch 383/400\n1430/1430 [==============================] - 0s 106us/sample - loss: 0.1762 - accuracy: 0.9315\nEpoch 384/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1593 - accuracy: 0.9413\nEpoch 385/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1960 - accuracy: 0.9294\nEpoch 386/400\n1430/1430 [==============================] - 0s 100us/sample - loss: 0.1681 - accuracy: 0.9336\nEpoch 387/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1894 - accuracy: 0.9273\nEpoch 388/400\n1430/1430 [==============================] - 0s 99us/sample - loss: 0.1827 - accuracy: 0.9287\nEpoch 389/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1488 - accuracy: 0.9448\nEpoch 390/400\n1430/1430 [==============================] - 0s 102us/sample - loss: 0.2001 - accuracy: 0.9238\nEpoch 391/400\n1430/1430 [==============================] - 0s 101us/sample - loss: 0.1754 - accuracy: 0.9336\nEpoch 392/400\n1430/1430 [==============================] - 0s 102us/sample - loss: 0.2158 - accuracy: 0.9210\nEpoch 393/400\n1430/1430 [==============================] - 0s 104us/sample - loss: 0.1997 - accuracy: 0.9252\nEpoch 394/400\n1430/1430 [==============================] - 0s 103us/sample - loss: 0.1629 - accuracy: 0.9343\nEpoch 395/400\n1430/1430 [==============================] - 0s 98us/sample - loss: 0.1631 - accuracy: 0.9350\nEpoch 396/400\n1430/1430 [==============================] - 0s 115us/sample - loss: 0.1875 - accuracy: 0.9308\nEpoch 397/400\n1430/1430 [==============================] - 0s 115us/sample - loss: 0.1960 - accuracy: 0.9294\nEpoch 398/400\n1430/1430 [==============================] - 0s 108us/sample - loss: 0.2030 - accuracy: 0.9273\nEpoch 399/400\n1430/1430 [==============================] - 0s 107us/sample - loss: 0.1726 - accuracy: 0.9371\nEpoch 400/400\n1430/1430 [==============================] - 0s 107us/sample - loss: 0.1801 - accuracy: 0.9343\nProcessed trackers: 100%|██████████| 28/28 [00:00<00:00, 684.68it/s, # actions=73]\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object NoneType can't be used in 'await' expression",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f8acde53bc78>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/dialogue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object NoneType can't be used in 'await' expression"
     ]
    }
   ],
   "source": [
    "from rasa.core.policies.policy import Policy\n",
    "from rasa.core.policies.registry import FallbackPolicy, KerasPolicy, MemoizationPolicy, FormPolicy, MappingPolicy\n",
    "from rasa.core.agent import Agent\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "agent = Agent('domain-papaito.yml',\n",
    "              policies=[MappingPolicy(),\n",
    "                        MemoizationPolicy(max_history=5),\n",
    "                        KerasPolicy(validation_split=0.1,epochs=400),\n",
    "                        FormPolicy(),\n",
    "                        fallback])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = await agent.load_data('data/core/stories-papaito.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "# Talk to your Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817",
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModelNotFound",
     "evalue": "No NLU or Core data for unpacked model at: 'models/dialogue'.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelNotFound\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-698aceb4591e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maction_endpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEndpointConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"http://0.0.0.0:5055/webhook\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/dialogue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_endpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_endpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#!docker run -d -p 5055:5055 --mount type=bind,source=/home/debian/workspace/Dadbot/actions/actions.py,target=/app/actions rasa/rasa-sdk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/rasa/core/agent.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path, interpreter, generator, tracker_store, lock_store, action_endpoint, model_server, remote_storage, path_to_model_archive)\u001b[0m\n\u001b[1;32m    417\u001b[0m             )\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mcore_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_subdirectories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnlu_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/rasa/model.py\u001b[0m in \u001b[0;36mget_model_subdirectories\u001b[0;34m(unpacked_model_path)\u001b[0m\n\u001b[1;32m    225\u001b[0m         raise ModelNotFound(\n\u001b[1;32m    226\u001b[0m             \"No NLU or Core data for unpacked model at: '{}'.\".format(\n\u001b[0;32m--> 227\u001b[0;31m                 \u001b[0munpacked_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             )\n\u001b[1;32m    229\u001b[0m         )\n",
      "\u001b[0;31mModelNotFound\u001b[0m: No NLU or Core data for unpacked model at: 'models/dialogue'."
     ]
    }
   ],
   "source": [
    "#Starting the Bot\n",
    "from rasa.core.agent import Agent\n",
    "from rasa.core.utils import EndpointConfig\n",
    "\n",
    "action_endpoint = EndpointConfig(url=\"http://0.0.0.0:5055/webhook\")\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory, action_endpoint=action_endpoint)\n",
    "\n",
    "#!docker run -d -p 5055:5055 --mount type=bind,source=/home/debian/workspace/Dadbot/actions/actions.py,target=/app/actions rasa/rasa-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the voice synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numba.decorators'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9e99fac73dbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtacotron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_hparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtacotron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTacotron2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtacotron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTacotronSTFT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtacotron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgriffin_lim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Dadbot/tacotron2/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask_from_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Dadbot/layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlibrosa_mel_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maudio_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_range_compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maudio_processing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_range_decompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/librosa/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# And all the librosa sub-modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/librosa/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtime_frequency\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspectrum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpitch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtime_frequency\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mframes_to_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_to_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameterError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/librosa/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdecorator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptional_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'moved'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optional_jit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numba.decorators'"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/NVIDIA/tacotron2.git\n",
    "\n",
    "from tacotron2.hparams import create_hparams\n",
    "from tacotron2.model import Tacotron2\n",
    "from tacotron2.layers import TacotronSTFT, STFT\n",
    "from tacotron2.audio_processing import griffin_lim\n",
    "from tacotron2.train import load_model\n",
    "from tacotron2.text import text_to_sequence\n",
    "from tacotron2.waveglow.mel2samp import files_to_list, MAX_WAV_VALUE\n",
    "from tacotron2.denoiser import Denoiser\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def synthesize(text, voice, sigma=0.6, denoiser_strength=0.05, is_fp16=False):\n",
    "\n",
    "    hparams = create_hparams()\n",
    "    hparams.sampling_rate = 22050\n",
    "\n",
    "    if voice == \"papaito\":\n",
    "        voice_model = \"nvidia_tacotron2_papaito_300\"\n",
    "    elif voice == \"constantino\":\n",
    "        voice_model = \"tacotron2_Constantino_600\"\n",
    "    elif voice == \"orador\":\n",
    "        voice_model = \"checkpoint_tacotron2_29000_es\"\n",
    "    \n",
    "    checkpoint_path = \"/home/debian/workspace/models/\" + voice_model\n",
    "        \n",
    "    model = load_model(hparams)\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "    _ = model.cuda().eval().half()\n",
    "\n",
    "    waveglow_path = '/home/debian/workspace/models/waveglow_256channels_ljs_v2.pt'\n",
    "    waveglow = torch.load(waveglow_path)['model']\n",
    "    _ = waveglow.cuda().eval().half()\n",
    "    denoiser = Denoiser(waveglow)\n",
    "\n",
    "    #text=\"¡Cágate lorito!\"\n",
    "    #with open(filelist_path, encoding='utf-8', mode='r') as f:\n",
    "    #    text = f.read()\n",
    "\n",
    "    sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(\n",
    "        torch.from_numpy(sequence)).cuda().long()\n",
    "\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "    #mel = torch.unsqueeze(mel, 0)\n",
    "    mel = mel_outputs.half() if is_fp16 else mel_outputs\n",
    "    audio = np.array([])\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel, sigma=sigma)\n",
    "        if denoiser_strength > 0:\n",
    "             audio = denoiser(audio, denoiser_strength)\n",
    "        audio = audio * MAX_WAV_VALUE\n",
    "        audio = audio.squeeze()\n",
    "        audio = audio.cpu().numpy()\n",
    "        audio = audio.astype('int16')\n",
    "    \n",
    "    return audio, hparams.sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "¡Da-bot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0b971d8762c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"¡Da-bot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quieto parao'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rasa/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from sty import fg, bg, ef, rs\n",
    "\n",
    "print(\"¡Da-bot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    \n",
    "    if a == 'quieto parao':\n",
    "        break\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        to_synth = response[\"text\"]\n",
    "        #to_synth = \"Esto es una prueba para ver si funciona\"\n",
    "        print(fg.blue + to_synth + fg.rs)\n",
    "        response_file = open('response.txt','w') \n",
    "        response_file.write(to_synth)\n",
    "        voice, sr = synthesize(to_synth, \"orador\")\n",
    "        sd.play(voice, sr)\n",
    "        response_file.close()        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Conversational_Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}