{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oxVq6vQ76r7"
   },
   "source": [
    "# Dadbot: Dad's memorial bot based on RASA (old style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kIFYA-Kp8aK4"
   },
   "source": [
    "## Starting Jupyter Notebook with necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0_7gOmu0r3v",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVAF41hr8jU5"
   },
   "source": [
    "# Installations\n",
    "* Rasa\n",
    "* SpaCy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4049
    },
    "colab_type": "code",
    "id": "UsvAOHF_1dAY",
    "outputId": "f65c2c83-e7ae-46ef-e800-e43dcb854766",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "#!{python} -m pip install -U pip\n",
    "#!{python} -m pip install tensorflow[tensorflow-addons]==2.1.0\n",
    "#!{python} -m pip install rasa[convert]~=1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wyCva14-1gD4",
    "outputId": "642d04c1-b9ad-4ed0-fb28-ee9bef21507b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{python} -m spacy download es_core_news_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Downloading the Spanish Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "eRmnEdML3OhH",
    "outputId": "cb852307-d652-40c3-cf3d-66c54f833908",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{python} -m spacy link es_core_news_md es --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7JQlbqR9CHC"
   },
   "source": [
    "## Import the Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSw6zFmk3iPu"
   },
   "outputs": [],
   "source": [
    "import rasa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEw5vhSq9gWa"
   },
   "source": [
    "# 1. Teaching the bot to understand user inputs using Rasa NLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieoWk91X9y8X"
   },
   "source": [
    "## Training the NLU Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "dp3AIHmS4L6x",
    "outputId": "8011c4f7-c789-4138-84d7-4710207615d8",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rasa.model import get_model\n",
    "from rasa.nlu import config, training_data, utils\n",
    "from rasa.nlu.utils import write_to_file\n",
    "from rasa.nlu.components import ComponentBuilder\n",
    "from rasa.nlu.config import RasaNLUModelConfig\n",
    "from rasa.nlu.model import Interpreter, Trainer, TrainingData\n",
    "from rasa.nlu.components import Component\n",
    "from rasa.nlu.tokenizers.tokenizer import Token\n",
    "from rasa.utils.tensorflow.constants import ENTITY_RECOGNITION\n",
    "\n",
    "import spacy\n",
    "\n",
    "#spacy_parser = spacy.load('es_core_news_md')\n",
    "#nlp = spacy.load('es')\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = training_data.loading.load_data(\"data/nlu/nlu-papaito.md\")\n",
    "\n",
    "# trainer to train our pipeline\n",
    "trainer = Trainer(config.load(\"config_simple.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jrfp4xOS95ZZ"
   },
   "source": [
    "## Evaluating the NLU model on a random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4UjzlqMV4N1k",
    "outputId": "37ea93e5-6a71-4e8e-d2b6-a45144d184ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A helper function for prettier output\n",
    "\n",
    "def pprint(o):   \n",
    "    print(json.dumps(o, indent=2))\n",
    "    \n",
    "pprint(interpreter.parse(\"dejándome el coche\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OPlSd-As-Fz4"
   },
   "source": [
    "## Evaluating the NLU model on a test data\n",
    "(Here we are using the data at hand i.e nlu.md but it isr recommended to use unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1483
    },
    "colab_type": "code",
    "id": "FmRCylbT4jyw",
    "outputId": "fd1bfd57-ebb3-4541-d3b3-b4cbba781164",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rasa.nlu.test import run_evaluation\n",
    "\n",
    "run_evaluation(\"data/nlu/nlu-papaito.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av3R2GZZ-WJO"
   },
   "source": [
    "# 2. Teaching the bot to respond using Rasa Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-jn1g_k-o-m"
   },
   "source": [
    "##  Visualising the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXZhTaSw9SNR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "#!breq install graphviz\n",
    "\n",
    "#!conda install -y -n rasa pygraphviz pkg-config;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1090
    },
    "colab_type": "code",
    "id": "O1gYRXe15amU",
    "outputId": "9c0838e3-56c1-4eeb-a879-cc09619269d3"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa.core.agent import Agent\n",
    " \n",
    "agent = Agent('domain-papaito.yml')\n",
    "#agent.visualize(\"data/core/stories-papaito.md\", \"story_graph.png\", max_history=2)\n",
    "#Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdKD3l7-ua8"
   },
   "source": [
    "## Training a Dialogue Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7364
    },
    "colab_type": "code",
    "id": "4D7R-FRO5dxz",
    "outputId": "727adf2a-fa4b-4158-df94-30ad472f62f3",
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "from rasa.core.policies.policy import Policy\n",
    "from rasa.core.policies.registry import FallbackPolicy, KerasPolicy, MemoizationPolicy, FormPolicy, MappingPolicy\n",
    "from rasa.core.agent import Agent\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.1)\n",
    "\n",
    "agent = Agent('domain-papaito.yml',\n",
    "              policies=[MappingPolicy(),\n",
    "                        MemoizationPolicy(max_history=5),\n",
    "                        KerasPolicy(validation_split=0.1,epochs=400),\n",
    "                        FormPolicy(),\n",
    "                        fallback])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = await agent.load_data('data/core/stories-papaito.md')\n",
    "\n",
    "agent.train(training_data)\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4911z6y-5rD"
   },
   "source": [
    "# Talk to your Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nE4coPam5hry",
    "outputId": "c8ec135b-882b-4e9e-a955-f3e184177817",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Starting the Bot\n",
    "from rasa.core.agent import Agent\n",
    "from rasa.core.utils import EndpointConfig\n",
    "\n",
    "action_endpoint = EndpointConfig(url=\"http://0.0.0.0:5055/webhook\")\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory, action_endpoint=action_endpoint)\n",
    "\n",
    "#!docker run -d -p 5055:5055 --mount type=bind,source=/home/debian/workspace/Dadbot/actions/actions.py,target=/app/actions rasa/rasa-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the voice synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/NVIDIA/tacotron2.git\n",
    "\n",
    "from tacotron2.hparams import create_hparams\n",
    "from tacotron2.model import Tacotron2\n",
    "from tacotron2.layers import TacotronSTFT, STFT\n",
    "from tacotron2.audio_processing import griffin_lim\n",
    "from tacotron2.train import load_model\n",
    "from tacotron2.text import text_to_sequence\n",
    "from tacotron2.waveglow.mel2samp import files_to_list, MAX_WAV_VALUE\n",
    "from tacotron2.denoiser import Denoiser\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def synthesize(text, voice, sigma=0.6, denoiser_strength=0.05, is_fp16=False):\n",
    "\n",
    "    hparams = create_hparams()\n",
    "    hparams.sampling_rate = 22050\n",
    "\n",
    "    if voice == \"papaito\":\n",
    "        voice_model = \"nvidia_tacotron2_papaito_300\"\n",
    "    elif voice == \"constantino\":\n",
    "        voice_model = \"tacotron2_Constantino_600\"\n",
    "    elif voice == \"orador\":\n",
    "        voice_model = \"checkpoint_tacotron2_29000_es\"\n",
    "    \n",
    "    checkpoint_path = \"/home/debian/workspace/models/\" + voice_model\n",
    "        \n",
    "    model = load_model(hparams)\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "    _ = model.cuda().eval().half()\n",
    "\n",
    "    waveglow_path = '/home/debian/workspace/models/waveglow_256channels_ljs_v2.pt'\n",
    "    waveglow = torch.load(waveglow_path)['model']\n",
    "    _ = waveglow.cuda().eval().half()\n",
    "    denoiser = Denoiser(waveglow)\n",
    "\n",
    "    #text=\"¡Cágate lorito!\"\n",
    "    #with open(filelist_path, encoding='utf-8', mode='r') as f:\n",
    "    #    text = f.read()\n",
    "\n",
    "    sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "    sequence = torch.autograd.Variable(\n",
    "        torch.from_numpy(sequence)).cuda().long()\n",
    "\n",
    "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
    "    #mel = torch.unsqueeze(mel, 0)\n",
    "    mel = mel_outputs.half() if is_fp16 else mel_outputs\n",
    "    audio = np.array([])\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel, sigma=sigma)\n",
    "        if denoiser_strength > 0:\n",
    "             audio = denoiser(audio, denoiser_strength)\n",
    "        audio = audio * MAX_WAV_VALUE\n",
    "        audio = audio.squeeze()\n",
    "        audio = audio.cpu().numpy()\n",
    "        audio = audio.astype('int16')\n",
    "    \n",
    "    return audio, hparams.sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "DDVLzhAT5yrP",
    "outputId": "aee3fc83-df97-42b4-c7e0-c8929f76337c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from sty import fg, bg, ef, rs\n",
    "\n",
    "print(\"¡Da-bot está listo para cascar! Escribe tus mensajes o dile 'quieto parao'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    \n",
    "    if a == 'quieto parao':\n",
    "        break\n",
    "    responses = agent.handle_text(a)\n",
    "    for response in responses:\n",
    "        to_synth = response[\"text\"]\n",
    "        #to_synth = \"Esto es una prueba para ver si funciona\"\n",
    "        print(fg.blue + to_synth + fg.rs)\n",
    "        response_file = open('response.txt','w') \n",
    "        response_file.write(to_synth)\n",
    "        #voice, sr = synthesize(to_synth, \"orador\")\n",
    "        #sd.play(voice, sr)\n",
    "        response_file.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Conversational_Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}